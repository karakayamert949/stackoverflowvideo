{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import winsound\n",
    "duration = 200  # milliseconds\n",
    "freq = 440  # Hz\n",
    "\n",
    "\n",
    "answerCount=0\n",
    "while answerCount==0:\n",
    "    initial_text=requests.get(\"https://stackoverflow.com/questions/tagged/python?sort=RecentActivity&edited=true\").text\n",
    "    soup=BeautifulSoup(initial_text,\"lxml\")\n",
    "    #questions=soup.find_all(\"div\",class_=\"s-post-summary js-post-summary\")\n",
    "    #print(questions)\n",
    "    question=soup.find(\"div\",class_=\"s-post-summary js-post-summary\")\n",
    "    #print(question)\n",
    "    answerCountTemp=question.find_all(\"span\",class_=\"s-post-summary--stats-item-number\")\n",
    "    answerCount=int(answerCountTemp[1].text)\n",
    "    time.sleep(1)\n",
    "#print(answerCountTemp)\n",
    "#print(answerCount)\n",
    "\n",
    "title=question.find(\"a\",class_=\"s-link\").text\n",
    "link=question.find(\"a\",class_=\"s-link\").get(\"href\")\n",
    "link=\"https://stackoverflow.com\"+link\n",
    "second_text=requests.get(link).text\n",
    "soup2=BeautifulSoup(second_text,\"lxml\")\n",
    "#question and solutions 0 is question 1 2 3.. are solutions\n",
    "qs=soup2.find_all(\"div\",class_=\"s-prose js-post-body\")\n",
    "question_text=qs[0].text\n",
    "with open(\"title.txt\",\"w\",encoding=\"utf-8\") as f2:\n",
    "    f2.truncate(0)\n",
    "    f2.write(title)\n",
    "with open(\"question.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.truncate(0)\n",
    "    f.write(question_text)\n",
    "solution=qs[1].text\n",
    "with open(\"solution1.txt\",\"w\",encoding=\"utf-8\") as f1:\n",
    "    f1.truncate(0)\n",
    "    f1.write(solution)\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "# text to speech\n",
    "import os\n",
    "from gtts import gTTS\n",
    "\n",
    "with open(\"title.txt\",\"r\") as f1:\n",
    "    f1=f1.read()\n",
    "    title=gTTS(text=f1,lang=\"en\")\n",
    "title.save(\"title.mp3\")\n",
    "\n",
    "with open(\"question.txt\",\"r\") as f2:\n",
    "    f2=f2.read()\n",
    "    title=gTTS(text=f2,lang=\"en\")\n",
    "title.save(\"question.mp3\")\n",
    "\n",
    "with open(\"solution1.txt\",\"r\") as f3:\n",
    "    f3=f3.read()\n",
    "    title=gTTS(text=f3,lang=\"en\")\n",
    "title.save(\"solution1.mp3\")\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#make screenshot\n",
    "from pynput.keyboard import Key,Controller\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyautogui\n",
    "\n",
    "text=\"title.txt\"\n",
    "k = Controller()\n",
    "k.press(Key.ctrl)\n",
    "k.press(\"p\")\n",
    "k.release(Key.ctrl)\n",
    "k.release(\"p\")\n",
    "time.sleep(0.5)\n",
    "for char in text:\n",
    "    k.tap(char)\n",
    "    time.sleep(0.12)\n",
    "time.sleep(0.12)\n",
    "k.tap(Key.enter)\n",
    "time.sleep(0.3)\n",
    "image = pyautogui.screenshot()\n",
    "image = cv2.cvtColor(np.array(image),cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(f\"title.png\", image)\n",
    "time.sleep(0.5)\n",
    "\n",
    "text=\"question.txt\"\n",
    "k.press(Key.ctrl)\n",
    "k.press(\"p\")\n",
    "k.release(Key.ctrl)\n",
    "k.release(\"p\")\n",
    "time.sleep(0.5)\n",
    "for char in text:\n",
    "    k.tap(char)\n",
    "    time.sleep(0.12)\n",
    "time.sleep(0.12)\n",
    "k.tap(Key.enter)\n",
    "time.sleep(0.2)\n",
    "image = pyautogui.screenshot()\n",
    "image = cv2.cvtColor(np.array(image),cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(f\"question.png\", image)\n",
    "time.sleep(0.5)\n",
    "\n",
    "text=\"solution1.txt\"\n",
    "k.press(Key.ctrl)\n",
    "k.press(\"p\")\n",
    "k.release(Key.ctrl)\n",
    "k.release(\"p\")\n",
    "time.sleep(0.5)\n",
    "for char in text:\n",
    "    k.tap(char)\n",
    "    time.sleep(0.12)\n",
    "time.sleep(0.12)\n",
    "k.tap(Key.enter)\n",
    "time.sleep(0.2)\n",
    "image = pyautogui.screenshot()\n",
    "image = cv2.cvtColor(np.array(image),cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite(f\"solution1.png\", image)\n",
    "time.sleep(0.5)\n",
    "\n",
    "text=\"main.ipynb\"\n",
    "k.press(Key.ctrl)\n",
    "k.press(\"p\")\n",
    "k.release(Key.ctrl)\n",
    "k.release(\"p\")\n",
    "time.sleep(0.5)\n",
    "for char in text:\n",
    "    k.tap(char)\n",
    "    time.sleep(0.12)\n",
    "time.sleep(0.12)\n",
    "k.tap(Key.enter)\n",
    "time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################3\n",
    "# crop image\n",
    "from PIL import Image\n",
    " \n",
    "# Opens a image in RGB mode\n",
    "im = Image.open(\"./title.png\")\n",
    " \n",
    "# Size of the image in pixels (size of original image)\n",
    "# (This is not mandatory)\n",
    "width, height = im.size\n",
    " \n",
    "# Setting the points for cropped image\n",
    "left = 326\n",
    "top = 100\n",
    "right = 1890\n",
    "bottom = 1040\n",
    " \n",
    "# Cropped image of above dimension\n",
    "# (It will not change original image)\n",
    "im1 = im.crop((left, top, right, bottom))\n",
    " \n",
    "# Shows the image in image viewer\n",
    "im1.save(\"title.png\")\n",
    "\n",
    "im = Image.open(\"./question.png\")\n",
    " \n",
    "# Size of the image in pixels (size of original image)\n",
    "# (This is not mandatory)\n",
    "width, height = im.size\n",
    " \n",
    "# Setting the points for cropped image\n",
    "left = 326\n",
    "top = 100\n",
    "right = 1890\n",
    "bottom = 1040\n",
    " \n",
    "# Cropped image of above dimension\n",
    "# (It will not change original image)\n",
    "im1 = im.crop((left, top, right, bottom))\n",
    " \n",
    "# Shows the image in image viewer\n",
    "im1.save(\"question.png\")\n",
    "\n",
    "im = Image.open(\"./solution1.png\")\n",
    " \n",
    "# Size of the image in pixels (size of original image)\n",
    "# (This is not mandatory)\n",
    "width, height = im.size\n",
    " \n",
    "# Setting the points for cropped image\n",
    "left = 326\n",
    "top = 100\n",
    "right = 1890\n",
    "bottom = 1040\n",
    " \n",
    "# Cropped image of above dimension\n",
    "# (It will not change original image)\n",
    "im1 = im.crop((left, top, right, bottom))\n",
    " \n",
    "# Shows the image in image viewer\n",
    "im1.save(\"solution1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#make video\n",
    "from moviepy.editor import AudioFileClip, ImageClip,concatenate_videoclips, VideoFileClip\n",
    "\n",
    "    # create the audio clip object\n",
    "audio_clip = AudioFileClip(\"./title.mp3\")\n",
    "# create the image clip object\n",
    "image_clip = ImageClip(\"./title.png\")\n",
    "# use set_audio method from image clip to combine the audio with the image\n",
    "video_clip = image_clip.set_audio(audio_clip)\n",
    "# specify the duration of the new clip to be the duration of the audio clip\n",
    "video_clip.duration = audio_clip.duration\n",
    "# set the FPS to 1\n",
    "video_clip.fps = 1\n",
    "# write the resuling video clip\n",
    "video_clip.write_videofile(\"./title.mp4\")\n",
    "\n",
    "audio_clip = AudioFileClip(\"./question.mp3\")\n",
    "# create the image clip object\n",
    "image_clip = ImageClip(\"./question.png\")\n",
    "# use set_audio method from image clip to combine the audio with the image\n",
    "video_clip = image_clip.set_audio(audio_clip)\n",
    "# specify the duration of the new clip to be the duration of the audio clip\n",
    "video_clip.duration = audio_clip.duration\n",
    "# set the FPS to 1\n",
    "video_clip.fps = 1\n",
    "# write the resuling video clip\n",
    "video_clip.write_videofile(\"./question.mp4\")\n",
    "\n",
    "audio_clip = AudioFileClip(\"./solution1.mp3\")\n",
    "# create the image clip object\n",
    "image_clip = ImageClip(\"./solution1.png\")\n",
    "# use set_audio method from image clip to combine the audio with the image\n",
    "video_clip = image_clip.set_audio(audio_clip)\n",
    "# specify the duration of the new clip to be the duration of the audio clip\n",
    "video_clip.duration = audio_clip.duration\n",
    "# set the FPS to 1\n",
    "video_clip.fps = 1\n",
    "# write the resuling video clip\n",
    "video_clip.write_videofile(\"./solution1.mp4\")\n",
    "\n",
    "##########\n",
    "#merge videos\n",
    "video_clip_paths=[\"./title.mp4\",\"./question.mp4\",\"./solution1.mp4\"]\n",
    "clips = [VideoFileClip(c) for c in video_clip_paths]\n",
    "final_clip = concatenate_videoclips(clips)\n",
    "final_clip.write_videofile(\"./video.mp4\")\n",
    "winsound.Beep(freq, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text=\"title.txt\"\n",
    "k = Controller()\n",
    "k.press(Key.alt)\n",
    "k.press(Key.tab)\n",
    "time.sleep(0.2)\n",
    "k.release(Key.alt)\n",
    "k.release(Key.tab)\n",
    "time.sleep(0.3)\n",
    "k.tap(Key.enter)\n",
    "time.sleep(0.2)\n",
    "\n",
    "pyautogui.dragRel(310, 670)\n",
    "pyautogui.click()\n",
    "time.sleep(0.2)\n",
    "\n",
    "text=\"video.mp4\"\n",
    "for char in text:\n",
    "    k.tap(char)\n",
    "    time.sleep(0.12)\n",
    "k.tap(Key.enter)\n",
    "time.sleep(1)\n",
    "\n",
    "with open(\"title.txt\",\"r\") as f1:\n",
    "    tit=f1.read()\n",
    "time.sleep(7.5)\n",
    "\n",
    "tit+=\"[SOLUTION]\"\n",
    "tit2=tit+\"[python]\"+\"                                            Original post link:\"+link\n",
    "tit=tit[0:100]\n",
    "for char in tit:\n",
    "    k.tap(char)\n",
    "    time.sleep(0.12)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(1)\n",
    "\n",
    "for char in tit2:\n",
    "    k.tap(char)\n",
    "    time.sleep(0.12)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.tab)\n",
    "time.sleep(0.1)\n",
    "k.tap(Key.down)\n",
    "time.sleep(0.1)\n",
    "\n",
    "pyautogui.dragRel(670, 160)\n",
    "pyautogui.click()\n",
    "time.sleep(0.2)\n",
    "pyautogui.click()\n",
    "time.sleep(0.2)\n",
    "pyautogui.click()\n",
    "time.sleep(7)\n",
    "pyautogui.dragRel(-1221, -78)\n",
    "time.sleep(0.1)\n",
    "pyautogui.click()\n",
    "time.sleep(0.5)\n",
    "pyautogui.dragRel(1221, 78)\n",
    "time.sleep(0.2)\n",
    "pyautogui.click()\n",
    "winsound.Beep(freq, duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19f8f9ebccd493d1979261b88c51ecd06bf2efdee26e5f5e5ddb3d1c8ea2e26f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
